---
title: "Dependent Random Weighting"
author: "Katherine Goode and Shan Yu"
date: "05/04/2018"
output:
  beamer_presentation:
    theme: "Singapore"
    colortheme: "dolphin"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction

We were interested in learning about resampling methods for irregularly spaced time series data. This led us to read the paper

\begin{quote}
"The Dependent Random Weighting" (2015) by Srijan Sengupta, Xiaofeng Shao, and Yingchuan Wang.
\end{quote}

The paper:
\begin{itemize}
\item Introduces a method that assigns random weights to the irregular time series data 
\vspace{0.25cm}
\item Weights are created using a dependence structure that mimics that of the observed data 
\end{itemize}

## Irregular Time Series Data

Irregular time series data can occur in two ways.

\vspace{0.25cm}

(1) \textbf{Missing Values}: Time series occurs at equally space intervals but not all data points are observed

\begin{center}
\includegraphics[height = 0.8cm]{./images/missing}
\end{center}

\vspace{0.25cm}

(2) \textbf{Unequal Intervals}: Times when the data are observed are generated from a 1-D point process

\begin{center}
\includegraphics[height = 0.8cm]{./images/unequal}
\end{center}


## Dependent Random Weighting 
\textbf{Assign a random weight to each observation}
\begin{itemize}
\item A stationary time series $\{X_t\}_{t \in \mathbb{Z}}.$ And the parameter of interest is $\theta=T(F)$, where $T$ is a given function and $F$ is the marginal distribution of $\{X_t\}$.
\vspace{0.25cm}
\item The estimator of $\theta$ is $\widehat{\theta_n}=T(F_n)$, where $F_n$ is the empirical distribution function based on observations $\{X_{t_j}\}_{j=1}^n$ and $t_j$ are the time points at which the data are observed. 
\vspace{0.25cm}
\item The random weighted empirical distribution $F_n^{\ast}$ is defined as 
$$F_n^{\ast}(x)=\sum_{i=1}^nw(t_i)I(X_{t_i} \leq x),$$
where $\{w(t_i)\}_{i=1}^n$ are the random weights.
\end{itemize}

## Dependent Random Weighting
\begin{itemize}
\item The bootstrap sample is $$\widehat{\theta}_{n,DRW}^{\ast}=T(F^{\ast}_n).$$
\item \textbf{Example:} If we are interest in the marginal expectation of $X_t$, then we have 
$$\bar{X}_{n,DRW}^{\ast}=\sum_{j=1}^{n}w(t_j)X_{t_j}.$$


\end{itemize}

## Generate Weights
\vspace{-0.2in}
\begin{itemize}
\item Assume the random weights $\{w(t_i)\}_{i=1}^n$ take the form
$$w(t_i)=\frac{Z(t_i)}{\sum_{i=1}^nZ(t_i)}.$$
\item $Z(t_i)$ are a realization from a \textbf{non-negative} and \textbf{$l-$dependent} process $Z(t),~t \in R$. 
\vspace{0.25cm}
\item $l$ plays a similar role as the block size in the moving block bootstrap.
\end{itemize}
## Generate Weights

\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Example:} 
$Z(t_i)=(Y(t_i)+c)^2$, where $\{Y(t_i)\}_{i=1}^n \sim N(0,\Sigma)$. $\Sigma$ is a $n \times n$ matrix with $\Sigma(i, j)=W\left(\frac{t_i-t_j}{l}\right)$, where $W(\cdot)$ is a symmetric kernel function.
\end{column}
\begin{column}{0.48\textwidth}
\includegraphics[height = 3.2cm]{./images/BartlettWindor.pdf}
\end{column}
\end{columns}
\vspace{0.1cm}
\begin{columns}
\begin{column}{0.49\textwidth}
\begin{center}
$l=2$
\end{center}
$$\left( \begin{array}{cccc}
1&0.5&0&0\\
0.5&1&0.5&0\\
0&0.5&1&0.5\\
0&0&0.5&1
\end{array}
\right)$$
\end{column}
\begin{column}{0.49\textwidth}
\begin{center}
$l=3$
\end{center}
$$\left( \begin{array}{cccc}
1&2/3&1/3&0\\
2/3&1&2/3&1/3\\
1/3&2/3&1&2/3\\
0&1/3&2/3&1
\end{array}
\right)$$
\end{column}
\end{columns}


## Equally Spaced Time Series

\textbf{Theorem 1.} Assume that the function $H$ is differentiable in a neighborhood of $\mu$, under the assumptions in paper, then
\footnotesize{$$
\sup_{x \in \mathbb{R}}|P[\sqrt{n}\{H(\bar{X}_n)-H(\mu)\} \leq x]-P^{\ast}[\sqrt{n}\{H(\bar{X}_{n,DRW})-H(\bar{X}_n)\}S_Z \leq x]| 
\to o_p(1).
$$}


## Irregularly Spaced Time Series

Based on a stochastic sampling design, $t_j=\lambda_nv_j$, where $v_j$ takes values in a Borel subset of $(-1/2, 1/2].$ Let $k=\lim_{n \to \infty n/\lambda_n}$.

\textbf{Theorem 2.} Under the assumptions in the paper, we have 

(i) if $k \in (0, \infty)$, then 
\footnotesize{$$
\sup_{x \in \mathbb{R}}|P[\sqrt{n}\{\bar{X}_n-\mu\} \leq x]-P^{\ast}[\sqrt{n}\{\bar{X}_{n,DRW}-\bar{X}_n\}S_Z \leq x]| 
\to o_p(1).
$$}
(i) if $k=\infty$, then 
\footnotesize{$$
\sup_{x \in \mathbb{R}}|P[\sqrt{\lambda_n}\{\bar{X}_n-\mu\} \leq x]-P^{\ast}[\sqrt{\lambda_n}\{\bar{X}_{n,DRW}-\bar{X}_n\}S_Z \leq x]| 
\to o_p(1).
$$}


## Our Simulations: Overview

We wanted to apply and compare DRW to methods learned in STAT 651. We decided to compare the following situations.

\begin{itemize}
\item \textbf{Methods}: DRW versus MBB
\vspace{0.25cm}
\item \textbf{Data}: MA versus AR time series
\vspace{0.25cm}
\item \textbf{Estimators}: mean versus median
\vspace{0.25cm}
\item \textbf{Bandwidth}: block size versus $l$-dependence
\end{itemize}

Note on irregular data type:
\begin{itemize}
\item Paper used unequal time intervals (type 2)
\vspace{0.25cm}
\item We used equal time intervals with missing values (type 1)
\end{itemize}

## Our Simulations: The Procedure

We used the following procedure for our simulations.

\begin{enumerate}
\item \textbf{Generate irregular time series of size $n=400$.}
\vspace{0.25cm}
\begin{enumerate}
\item[(i)] Simulate $Y_t$ for $t=1,...,n$ from
\begin{itemize}
\item an MA(2) process with $\mu=0$, $\theta_1=-1$, and $\theta_2=0.7$ or
\item an AR(2) process with $\mu=0$, $\phi_1=-0.1$, or $\phi_2=0.6$.
\end{itemize}
\item[(ii)] Assign a weight $\omega_t$ to $Y_t$ where
  $$\omega_t=\sin\left(\frac{\pi \cdot t}{n}\right).$$
\item[(iii)] Generate $X_t\sim binomial(\omega_t)$ for $t=1,...,n$.
\item[(iv)] Let
  $$X_t=\begin{cases} Y_t & \mbox{ if } X_t=1 \\ \mbox{missing} & \mbox{ if } X_t=0
  \end{cases}$$
for $t=1,...,n$.
\item[(v)] Re-index the non-missing $X_t$ as $X_i$ for $i$ from $1$ to $n_j$ and use as the observed sample.
\end{enumerate}
\end{enumerate}

## Our Simulations: The Procedure

\begin{enumerate}
\item[2.] \textbf{Let $\ell=1$, and apply the resampling method to $K=1000$ samples.}
\vspace{0.25cm}
\begin{itemize}
\item MBB: Draw block bootstrap samples from $X_1,...,X_{n_j}$ with blocks of size $b=\ell$. (ignores missing values)
\vspace{0.1cm}
\item DRW: Randomly assign weights to $X_1,...,X_{n_j}$ using the method from the paper assuming $m$-dependence with $m=\ell$.
\end{itemize}
\vspace{0.25cm}
\item[3.] \textbf{Compute the mean and median from the $K$ samples.}
\vspace{0.25cm}
\item[4.] \textbf{Use the distributions of means and medians to compute evaluative measures.}
\vspace{0.25cm}
\begin{itemize}
\item Determine if the 95\% confidence interval contains the true value. (True process medians were approximated using 100,000 Monte Carlo simulations.)
\vspace{0.1cm}
\item Compute the standard deviation of the distribution. (Denote this as $\sigma_{n_j}^{(j)}/\sqrt{n_j}$.)
\end{itemize}
\end{enumerate}

## Our Simulations: The Procedure

\begin{enumerate}
\item[5.] \textbf{Repeat steps 1 to 4 for $M=500$ times.}
\vspace{0.25cm}
\item[6.] \textbf{Compute final evaluative measures.}
\vspace{0.25cm}
\begin{itemize}
\item Coverage rate for both the mean and median
\vspace{0.1cm}
\item Normalized MSE: 
  $$\frac{1}{M}\sum_{j=1}^M\left(\frac{n_j\sigma_{n_j}^{(j)}}{n\sigma_n}-1\right)^2$$
where $\sigma_n=\sqrt{n}Var(\hat{\theta}_n)$ with $\hat{\theta}_n$ denoting the estimator of interest, was approximated using 100,000 Monte Carlo simulations for both the mean and median
\end{itemize}
\vspace{0.25cm}
\item[7.] \textbf{Repeat steps 1 to 6 for $\ell=2,...,10$.}
\end{enumerate}

## Our Simulations: Results for Means

\begin{center}
\includegraphics[height = 3in]{./images/resmean.pdf}
\end{center}

## Our Simulations: Results for Medians

\begin{center}
\includegraphics[height = 3in]{./images/resmedian.pdf}
\end{center}

## Our Simulations: Results for Computing Time

We wanted to compare computing times since the paper mentioned that DRW should be easier to implement.
\begin{itemize}
\item MBB simulations run on a personal computer
\item DRW simulations run on the ISU Condo Cluster
\end{itemize}
We found that the process took much longer for the DRW than the MBB even when run on a more powerful computer.

\vspace{0.25cm}

\begin{center}
\begin{table}
\begin{tabular}{ccc}
\hline
& MBB (personal computer) & DRW (ISU Condo) \\
\hline
AR & 24.9 & \\
MA & 24.6 & \\
\hline
\end{tabular}
\caption{Computing times (in minutes) for full simulation process within a category}
\end{table}
\end{center}

## Conclusions

Our simulations provided us with the following information.
\begin{itemize}
\item DRW results were...than MBB results
\item DRW took more computation time than MBB
\end{itemize}

It would be interesting to run more simulations to consider:
\begin{itemize}
\item Would results change if different parameters were used to simulate AR and MA processes?
\item How would different amounts or locations of missingness affect the results?
\item Would different sample sizes affect the results?
\end{itemize}
