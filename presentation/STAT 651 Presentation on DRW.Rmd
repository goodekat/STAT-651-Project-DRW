---
title: "Dependent Random Weighting"
author: "Katherine Goode and Shan Yu"
date: "05/04/2018"
output:
  beamer_presentation:
    theme: "Singapore"
    colortheme: "dolphin"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Introduction

We were interested in learning about resampling methods for irregularly spaced time series data. This led us to read the paper

\begin{quote}
"The Dependent Random Weighting" (2015) by Srijan Sengupta, Xiaofeng Shao, and Yingchuan Wang.
\end{quote}

The paper:
\begin{itemize}
\item Introduces a method that assigns random weights to the irregular time series data 
\vspace{0.25cm}
\item Weights are created using a dependence structure that mimics that of the observed data 
\end{itemize}

## Irregular Time Series Data

Irregular time series data can occur in two ways.

\vspace{0.25cm}

(1) \textbf{Missing Values}: Time series occurs at equally space intervals but not all data points are observed

\begin{center}
\includegraphics[height = 0.8cm]{./images/missing}
\end{center}

\vspace{0.25cm}

(2) \textbf{Unequal Intervals}: Times when the data are observed are generated from a 1-D point process

\begin{center}
\includegraphics[height = 0.8cm]{./images/unequal}
\end{center}

## Dependent Random Weighting (the process)
\begin{itemize}
\item A stationary time series $\{X_t\}_{t \in \mathbb{Z}}.$ And the parameter of interest is $\theta=T(F)$, where $T$ is a given function and $F$ is the marginal distribution of $\{X_t\}$.
\vspace{0.25cm}
\item The estimator of $\theta$ is $\widehat{\theta_n}=T(F_n)$, where $F_n$ is the empirical distribution function based on observations $\{X_{t_j}\}_{j=1}^n$ and $t_j$ are the time points at which the data are observed. 
\vspace{0.25cm}
\item The random weighted empirical distribution $F_n^{\ast}$ is defined as 
$$F_n^{\ast}(x)=\sum_{i=1}^nw(t_i)I(X_{t_i} \leq x),$$
where $\{w(t_i)\}_{i=1}^n$ are the random weights.
\end{itemize}

## Dependent Random Weighting
\begin{itemize}
\item The bootstrap sample is $$\widehat{\theta}_{n,DRW}^{\ast}=T(F^{\ast}_n).$$
\item \textbf{Example:} If we are interest in the marginal expectation of $X_t$, then we have 
$$\bar{X}_{n,DRW}^{\ast}=\sum_{j=1}^{n}w(t_j)X_{t_j}.$$


\end{itemize}

## Dependent Random Weighting (theorems)
\vspace{-0.2in}
\begin{itemize}
\item Assume the random weights $\{w(t_i)\}_{i=1}^n$ take the form
$$w(t_i)=\frac{Z(t_i)}{\sum_{i=1}^nZ(t_i)}.$$
\item $Z(t_i)$ are a realization from a \textbf{non-negative} and \textbf{$l-$dependent} process $Z(t),~t \in R$. 
\vspace{0.25cm}
\item \textbf{Example:} 
$Z(t_i)=(Y(t_i)+c)^2$, where $\{Y(t_i)\}_{i=1}^n \sim N(0,\Sigma)$. $\Sigma$ is a $n \times n$ matrix with $\Sigma(i, j)=W\left(\frac{t_i-t_j}{l}\right)$, where $W(\cdot)$ is a symmetric kernel function.
\begin{center}
\includegraphics[height = 2cm]{./images/BartlettWindor.pdf}
\end{center}
\end{itemize}

## Dependent Random Weighting (their simulations)
...

## Our Simulations: Overview

We wanted to apply and compare DRW to methods learned in STAT 651. We decided to compare the following situations.

\begin{itemize}
\item \textbf{Methods}: DRW versus MBB
\vspace{0.25cm}
\item \textbf{Data}: MA versus AR time series
\vspace{0.25cm}
\item \textbf{Estimators}: mean versus median
\vspace{0.25cm}
\item \textbf{Bandwidth}: blocksize versus $l$-dependence
\end{itemize}

Note on irregular data type:
\begin{itemize}
\item Paper used unequal time intervals (type 2)
\vspace{0.25cm}
\item We used equal time intervals with missing values (type 1)
\end{itemize}

## Our Simulations: The Procedure

We used the following procedure for our simulations.

\begin{enumerate}
\item \textbf{Generate irregular time series of size $n=200$.}
\vspace{0.25cm}
\begin{enumerate}
\item[(i)] Simulate $y_t$ for $t=1,...,n$ from
\begin{itemize}
\item an MA process with $\mu=0$, $\theta_1=-1$, and $\theta_2=0.7$ or
\item an AR process with $\mu=0$, $\phi_1=-0.1$, or $\phi_2=0.6$).
\end{itemize}
\item[(ii)] Assign a weight $\omega_t$ to $y_t$ where
  $$\omega_t=\sin\left(\frac{\pi \cdot t}{n}\right).$$
\item[(iii)] Generate $z_t\sim binomial(\omega_t)$ for $t=1,...,n$.
\item[(iv)] Let
  $$x_t=\begin{cases} y_t & \mbox{ if } z_t=1 \\ \mbox{missing} & \mbox{ if } z_t=0
  \end{cases}$$
for $t=1,...,n$.
\item[(v)] Reindex the non-missing $x_t$ as $x_i$ for $i$ from $1$ to $n_j$ and use as the observed sample.
\end{enumerate}
\end{enumerate}

## Our Simulations: The Procedure

\begin{enumerate}
\item[2.] \textbf{Let $\ell=1$, and apply the resampling method to $K=1000$ samples.}
\vspace{0.25cm}
\begin{itemize}
\item MBB: Draw block bootstrap samples from $x_1,...,x_{n_j}$ with blocks of size $b=\ell$. (ignores missing values)
\vspace{0.1cm}
\item DRW: Randomly assign weights to $x_1,...,x_{n_j}$ using the method from the paper assuming $m$-dependence with $m=\ell$.
\end{itemize}
\vspace{0.25cm}
\item[3.] \textbf{Compute the mean and median from the $K$ samples.}
\vspace{0.25cm}
\item[4.] \textbf{Use the distributions of means and medians to compute evaluative measures.}
\vspace{0.25cm}
\begin{itemize}
\item Determine if the 95\% confidence interval contains the true value. (Note: True process medians were approximated using 100,000 Monte Carlo simulations.)
\vspace{0.1cm}
\item Compute the standard deviation of the distribution. (Denote this as $\sigma_{n_j}^{(j)}/\sqrt{n_j}$.)
\end{itemize}
\end{enumerate}

## Our Simulations: The Procedure

\begin{enumerate}
\item[5.] \textbf{Repeat steps 1 to 4 for $M=500$ times.}
\vspace{0.25cm}
\item[6.] \textbf{Compute final evaluative measures.}
\vspace{0.25cm}
\begin{itemize}
\item Coverage rate for both the mean and median
\vspace{0.1cm}
\item MSE: 
  $$\frac{1}{M}\sum_{j=1}^M\left(\frac{\sigma_{n_j}^{(j)}}{\sqrt{n_j}}-
  \frac{\sigma_n}{\sqrt{n}}\right)^2$$
\vspace{0.1cm}
\item Normalized MSE: 
  $$\frac{1}{M}\sum_{j=1}^M\left(\frac{n_j\sigma_{n_j}^{(j)}}{n\sigma_n}-1\right)^2$$
\item Note: $\sigma_n=\sqrt{n}Var(\hat{\theta}_n)$ where $\hat{\theta}_n$ is the estimator of interest. $\sigma_n$ was approximated using 100,000 Monte Carlo simulations for both the mean and median.
\end{itemize}
\vspace{0.25cm}
\item[7.] \textbf{Repeat steps 1 to 6 for $\ell=2,...,10$.}
\end{enumerate}

## Our Simulations: Results for Means
...

## Our Simulations: Results for Medians
...

## Our Simulations: Results for Computing Time
...

## Conclusion and Ideas for Future Work
...
